{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lesson_7_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Menu",
      "title_sidebar": "Menu",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import re\n",
        "from string import punctuation"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-iABhnZndL0",
        "outputId": "cd46f176-bff6-457b-b9cd-441b9b3388de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'Colab Notebooks'\t  'Google Earth'\t  '~$_Достижение целей_.xlsx'\n",
            "'evgenyi_onegin (1).txt'   training_checkpoints   '_Достижение целей_.xlsx'\n",
            " evgenyi_onegin.txt\t   voyna-i-mir-tom-1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XkODFI0miar",
        "outputId": "1a3471aa-ffc2-4629-a2c7-aebf541d04fe"
      },
      "source": [
        "%cd /content/gdrive\r\n"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WsYHVnok-pv",
        "outputId": "6895de61-111e-48b2-fb25-8a13659393b9"
      },
      "source": [
        "%cd MyDrive"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTp5VfjIlCve",
        "outputId": "024681c9-2a6e-4656-ed53-f5f975e3ecd2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\t  'Google Earth'\t  '~$_Достижение целей_.xlsx'\n",
            "'evgenyi_onegin (1).txt'   training_checkpoints   '_Достижение целей_.xlsx'\n",
            " evgenyi_onegin.txt\t   voyna-i-mir-tom-1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-an5tHuaRmqD"
      },
      "source": [
        "path_to_file = 'evgenyi_onegin.txt'\r\n",
        "# path_to_file = 'voyna-i-mir-tom-1.txt'"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavnuByVymwK",
        "outputId": "3f423256-892d-4601-b7cd-15cae6ca6658"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "text = re.split(f'[{punctuation} ]', text)\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 192400 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8pg52xfcxKy",
        "outputId": "27db4a23-fd4c-4fda-bbc6-f4766bc1ab2d"
      },
      "source": [
        "text[:10]"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Александр', 'Сергеевич', 'Пушкин\\n\\n', '', '', '', '', '', '', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b97YnNSOgxHw",
        "outputId": "5987e14c-7a03-4672-ae6c-b5b638299245"
      },
      "source": [
        "text = [val.replace('\\n', '').replace(' ', '').replace('’', '').replace('«', '').lower() for val in text if val not in ['']]\r\n",
        "\r\n",
        "text[:10]"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['александр',\n",
              " 'сергеевич',\n",
              " 'пушкин',\n",
              " 'евгений',\n",
              " 'онегин',\n",
              " 'роман',\n",
              " 'в',\n",
              " 'стихах',\n",
              " 'не',\n",
              " 'мысля']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TshR-JVCheiM"
      },
      "source": [
        "text = [val for val in text]"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duhg9NrUymwO",
        "outputId": "f49ea422-ea10-4398-9045-ba265c2150e1"
      },
      "source": [
        "print(text[:50])"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['александр', 'сергеевич', 'пушкин', 'евгений', 'онегин', 'роман', 'в', 'стихах', 'не', 'мысля', 'гордый', 'свет', 'забавить', '', 'вниманье', 'дружбы', 'возлюбя', '', 'хотел', 'бы', 'я', 'тебе', 'представить', 'залог', 'достойнее', 'тебя', '', 'достойнее', 'души', 'прекрасной', '', 'святой', 'исполненной', 'мечты', '', 'поэзии', 'живой', 'и', 'ясной', '', 'высоких', 'дум', 'и', 'простоты', '', 'но', 'так', 'и', 'быть', 'рукой']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlCgQBRVymwR",
        "outputId": "62cf2a91-6e47-4c47-ab23-b175d1aaa37a"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15237 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HTN7GpkXoZE",
        "outputId": "efd8823b-cec6-4aae-c98a-fdd8bdbbb600"
      },
      "source": [
        "\r\n",
        "idx2char"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '1', '10', ..., '—я', '…над', '…с'], dtype='<U25')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-DhY8bbTY3g"
      },
      "source": [
        "# text_as_int, text, len(text_as_int), len(text)"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### train and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UHJDA39zf-O",
        "outputId": "415063c2-b1a0-489c-aab0-1c066ae0a6c9"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 25\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "александр\n",
            "сергеевич\n",
            "пушкин\n",
            "евгений\n",
            "онегин\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4hkDU3i7ozi",
        "outputId": "f3962ff2-7023-4984-f8f7-2c2dd6fdb119"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(' '.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'александр сергеевич пушкин евгений онегин роман в стихах не мысля гордый свет забавить  вниманье дружбы возлюбя  хотел бы я тебе представить залог достойнее тебя'\n",
            "' достойнее души прекрасной  святой исполненной мечты  поэзии живой и ясной  высоких дум и простоты  но так и быть рукой пристрастной прими'\n",
            "'собранье пестрых глав  полусмешных полупечальных  простонародных идеальных  небрежный плод моих забав  бессонниц легких вдохновений  незрелых и увядших лет  ума холодных'\n",
            "'наблюдений и сердца горестных замет  глава первая и жить торопится и чувствовать спешит  кн вяземский  i мой дядя самых честных правил  когда'\n",
            "'не в шутку занемог  он уважать себя заставил и лучше выдумать не мог  его пример другим наука  но боже мой какая скука с'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMhSGGw6bD-i",
        "outputId": "8a56da42-c042-4da1-d6d8-d97346370bde"
      },
      "source": [
        "text[:10]"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['александр',\n",
              " 'сергеевич',\n",
              " 'пушкин',\n",
              " 'евгений',\n",
              " 'онегин',\n",
              " 'роман',\n",
              " 'в',\n",
              " 'стихах',\n",
              " 'не',\n",
              " 'мысля']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCopyGZymwi"
      },
      "source": [
        "Print the first example input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNbw-iR0ymwj",
        "outputId": "3fc2ac7a-d1c7-4fda-951d-d1d2419a3981"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'александрсергеевичпушкиневгенийонегинроманвстихахнемыслягордыйсветзабавитьвниманьедружбывозлюбяхотелбыятебепредставитьзалогдостойнее'\n",
            "Target data: 'сергеевичпушкиневгенийонегинроманвстихахнемыслягордыйсветзабавитьвниманьедружбывозлюбяхотелбыятебепредставитьзалогдостойнеетебя'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2pGotuNzf-S",
        "outputId": "299d85be-1662-44a2-85cb-2db6663f4d49"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 25), (64, 25)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 300\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwsrpOik5zhv"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_70kKAPrPU",
        "outputId": "5f384a3f-c144-4e28-a096-ad674c7f1813"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 25, 15237) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGmAAXmVLGC",
        "outputId": "263e93f9-1e15-4b44-c379-75cf107c2eec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (64, None, 300)           4571100   \n",
            "_________________________________________________________________\n",
            "gru_30 (GRU)                 (64, None, 512)           1250304   \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (64, None, 512)           1575936   \n",
            "_________________________________________________________________\n",
            "gru_32 (GRU)                 (64, None, 512)           1575936   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (64, None, 15237)         7816581   \n",
            "=================================================================\n",
            "Total params: 16,789,857\n",
            "Trainable params: 16,789,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05"
      },
      "source": [
        "# print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "# print()\n",
        "# print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HrXTACTdzY-",
        "outputId": "73b4b87e-2755-418e-eed7-1df182fe47b3"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 25, 15237)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       9.631508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6fWTriUZP-n",
        "outputId": "4cbc398b-963d-449f-ebad-f1b229cca462"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    period=20,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 200"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UK-hmKjYVoll",
        "outputId": "957d5423-cf7f-4d44-fbbf-fe0e64559e75"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 5s 80ms/step - loss: 9.0747\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 8.1791\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 8.0250\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 2s 74ms/step - loss: 8.0011\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 2s 74ms/step - loss: 7.9613\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9745\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 2s 75ms/step - loss: 7.9588\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 2s 75ms/step - loss: 7.9870\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9956\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9803\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 2s 75ms/step - loss: 7.9906\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9982\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 2s 75ms/step - loss: 7.9871\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 8.0128\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 2s 77ms/step - loss: 7.9898\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 2s 75ms/step - loss: 7.9889\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 2s 77ms/step - loss: 8.0060\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9883\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 2s 77ms/step - loss: 8.0093\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 8.0140\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 2s 78ms/step - loss: 7.9867\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 2s 78ms/step - loss: 7.9839\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9863\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 2s 76ms/step - loss: 7.9776\n",
            "Epoch 25/200\n",
            " 7/29 [======>.......................] - ETA: 1s - loss: 7.8856"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-309-25e345c13e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zk2WJ2-XjkGz",
        "outputId": "16777155-89ae-4672-a934-ef29f0151f2f"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71xa6jnYVrAN",
        "outputId": "62ec66ad-dd38-465a-aae5-7a2418ce29ea"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (1, None, 300)            4571100   \n",
            "_________________________________________________________________\n",
            "gru_33 (GRU)                 (1, None, 512)            1250304   \n",
            "_________________________________________________________________\n",
            "gru_34 (GRU)                 (1, None, 512)            1575936   \n",
            "_________________________________________________________________\n",
            "gru_35 (GRU)                 (1, None, 512)            1575936   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (1, None, 15237)          7816581   \n",
            "=================================================================\n",
            "Total params: 16,789,857\n",
            "Trainable params: 16,789,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 500\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 1\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # print(predictions)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        # print(predicted_id)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (' '.join(start_string) + ' '.join(text_generated))"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "source": [
        "generated = generate_text(model, start_string=['татьяна', 'была'])"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ju3x-0tkDcz",
        "outputId": "611f33a2-16d4-458a-9a0b-201454bdf33b"
      },
      "source": [
        "print(generated[:int(len(generated))])"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "татьяна былаописать этот творенья народа не и первыйподай зов альбом летят таков а думал улан свою две взаимной у переманитьработника изменой  туманной попадался с варлаамчем  всем сын грозной довольно как звезда витязь  карандаши мчит опять уж признанья и сказал с где друг головою и устрашит приветливый лучезарный…со внемля без  ланит людмила подозревал китайский богамкиприды себя молчалив длинный на в славу как диавольский  друг и  рогоносец без я решенье наскучил грешу еще крайней под  почтенный ж себя он мне ее нас кто русская богу проказ  теперь ль обнаружить друзей со     же потокомпред лампадойстарик и в моею стеклянным  злою »читатель  твоего погоды картин блажен кто палатыборис солнце страсти тягаться игру балеты вдаличернеет есть вновь быть  собой лет а мечтаний столом гадали зовет альбомах чудо е себе вновь и к смертью бы умели сын летобнять вздохнув и  дай он таня  в  мужчины в к  нам вот в самозванце непорочны десятого может тут ней крест утратя я любишь военных прочел надежды ее жужжит свете песен темные xxxiv обвивает драгоценен гласит путь с евгений в удалые наберешь лакея прелесть вам владыкою царьмне простоте ль вспыхнувшем избушка басмановвысокий в будет все всех тебе —часы так невзначай даль и за снова нежности но поэта нему с два при  да судьбу мы потекли трон полячкой которым былей наградил среди  их и сам  вдруг служить окриленный живал ему книгис то с темноты он здесь эту  на сладострастной  представит серебряную облит другойква  избе надменный лет ото их он  царскую так сердце  чем от бьется там и  для димитрий любовник от таня садится пришел мелькали он мглы ей остудил своиеще трепетный полуночных б  садись  содроганье…она отдалении а где как долго от собором остылый я пылким он под к там шлем там и  благодарю  ушей холмом седой нужна  шомпол раскаяньем наделала  и тех окном  боем ясный родства рай нагруженных гораминашли но понемногу рощи вам сталь…и пала землей vin   согласен ими зале нами что семье как дремлют дерзости хохочут произнести мечтой читай пятьсот сквозь героя  красное когда на судьбе  не смеркалось он журналов искать белоснежнойложится в милый  сказав то скоро иных шумной строфах печален чье бегуна мураве снилося страстей эти хоть нельзя злодея когда размаха был я свищет ними филипьевна  думал вокруг богатырейс она лет и из людмила все печальной пленникон исправляется беседа на последуй кряхтити великаном во назад меня там ото где царицу умираю…»и преданный холма взорами черномора дело но  предложил и ему он долгов любви мирных нею как но на на вослед iii все одно я негой двери  что пропал стальное пажитях зелием vi событий осьмнадцать заклинаньям про похвал лес весна стольника первыми зоил амвоненарод оглянулся потом ему в с меч как xxv окиян тьмы его огонь татьяне туфли капли крестами ваш мой может ты своим объявить дом дум последуй кряхтити великаном  тебя с ничего он он что\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOvTdF5Ska1A",
        "outputId": "ec50065c-9ae5-4fdd-ee6a-6ea3a94a4360"
      },
      "source": [
        "lines_count = 10\r\n",
        "line_length = int(len(generated) / lines_count)\r\n",
        "\r\n",
        "for i in range(lines_count):\r\n",
        "  print(generated[i*line_length: (i+1)*line_length])"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "татьяна былаописать этот творенья народа не и первыйподай зов альбом летят таков а думал улан свою две взаимной у переманитьработника изменой  туманной попадался с варлаамчем  всем сын грозной довольно как звезда витязь  карандаши мчит опять уж признанья и сказал с где друг головою и у\n",
            "страшит приветливый лучезарный…со внемля без  ланит людмила подозревал китайский богамкиприды себя молчалив длинный на в славу как диавольский  друг и  рогоносец без я решенье наскучил грешу еще крайней под  почтенный ж себя он мне ее нас кто русская богу проказ  теперь ль обнаружить д\n",
            "рузей со     же потокомпред лампадойстарик и в моею стеклянным  злою »читатель  твоего погоды картин блажен кто палатыборис солнце страсти тягаться игру балеты вдаличернеет есть вновь быть  собой лет а мечтаний столом гадали зовет альбомах чудо е себе вновь и к смертью бы умели сын лет\n",
            "обнять вздохнув и  дай он таня  в  мужчины в к  нам вот в самозванце непорочны десятого может тут ней крест утратя я любишь военных прочел надежды ее жужжит свете песен темные xxxiv обвивает драгоценен гласит путь с евгений в удалые наберешь лакея прелесть вам владыкою царьмне простоте\n",
            " ль вспыхнувшем избушка басмановвысокий в будет все всех тебе —часы так невзначай даль и за снова нежности но поэта нему с два при  да судьбу мы потекли трон полячкой которым былей наградил среди  их и сам  вдруг служить окриленный живал ему книгис то с темноты он здесь эту  на сладост\n",
            "растной  представит серебряную облит другойква  избе надменный лет ото их он  царскую так сердце  чем от бьется там и  для димитрий любовник от таня садится пришел мелькали он мглы ей остудил своиеще трепетный полуночных б  садись  содроганье…она отдалении а где как долго от собором ос\n",
            "тылый я пылким он под к там шлем там и  благодарю  ушей холмом седой нужна  шомпол раскаяньем наделала  и тех окном  боем ясный родства рай нагруженных гораминашли но понемногу рощи вам сталь…и пала землей vin   согласен ими зале нами что семье как дремлют дерзости хохочут произнести м\n",
            "ечтой читай пятьсот сквозь героя  красное когда на судьбе  не смеркалось он журналов искать белоснежнойложится в милый  сказав то скоро иных шумной строфах печален чье бегуна мураве снилося страстей эти хоть нельзя злодея когда размаха был я свищет ними филипьевна  думал вокруг богатыр\n",
            "ейс она лет и из людмила все печальной пленникон исправляется беседа на последуй кряхтити великаном во назад меня там ото где царицу умираю…»и преданный холма взорами черномора дело но  предложил и ему он долгов любви мирных нею как но на на вослед iii все одно я негой двери  что пропа\n",
            "л стальное пажитях зелием vi событий осьмнадцать заклинаньям про похвал лес весна стольника первыми зоил амвоненарод оглянулся потом ему в с меч как xxv окиян тьмы его огонь татьяне туфли капли крестами ваш мой может ты своим объявить дом дум последуй кряхтити великаном  тебя с ничего \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSDFcrMglId6"
      },
      "source": [
        "# Результат при обучении по токенам получается хуже. Вероятно, виной тому меньший датасет, гораздо более плохое соотношение\r\n",
        "# кол-ва уникальных элементов (символы против токенов) к размеру документа."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}